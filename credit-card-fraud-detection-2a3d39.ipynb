{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6492730,"sourceType":"datasetVersion","datasetId":3752264}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:49.123635Z","iopub.execute_input":"2025-09-20T11:47:49.124578Z","iopub.status.idle":"2025-09-20T11:47:49.135322Z","shell.execute_reply.started":"2025-09-20T11:47:49.124534Z","shell.execute_reply":"2025-09-20T11:47:49.134398Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata = pd.read_csv(\"/kaggle/input/credit-card-fraud-detection-dataset-2023/creditcard_2023.csv\", usecols=lambda col: col != 'id')\nprint(data.shape)\npd.set_option('display.max_column', None)\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:49.143274Z","iopub.execute_input":"2025-09-20T11:47:49.143765Z","iopub.status.idle":"2025-09-20T11:47:54.249742Z","shell.execute_reply.started":"2025-09-20T11:47:49.143736Z","shell.execute_reply":"2025-09-20T11:47:54.2485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Taking only small portion of data \nprint(\"Actual Datasize : \",data.shape)\ndata = data.sample(50000)\nprint(\"Reduced Datasize : \",data.shape)\n\ndata2 = data.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.251498Z","iopub.execute_input":"2025-09-20T11:47:54.252045Z","iopub.status.idle":"2025-09-20T11:47:54.293741Z","shell.execute_reply.started":"2025-09-20T11:47:54.252017Z","shell.execute_reply":"2025-09-20T11:47:54.292835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.isnull().sum()\n# Data has no null values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.294603Z","iopub.execute_input":"2025-09-20T11:47:54.294871Z","iopub.status.idle":"2025-09-20T11:47:54.30855Z","shell.execute_reply.started":"2025-09-20T11:47:54.29485Z","shell.execute_reply":"2025-09-20T11:47:54.307361Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_cols = data.select_dtypes(include=['object']).columns\nprint(\"Categorical Columns ; \", cat_cols)\n\nint_cols = [col for col in data.columns if col not in cat_cols]\nprint(\"Non-categorical Columns ; \", int_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.310463Z","iopub.execute_input":"2025-09-20T11:47:54.310753Z","iopub.status.idle":"2025-09-20T11:47:54.330545Z","shell.execute_reply.started":"2025-09-20T11:47:54.310731Z","shell.execute_reply":"2025-09-20T11:47:54.32945Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Column names are not present because They are created in a result of PCA. ","metadata":{}},{"cell_type":"code","source":"data['Class'].value_counts()\n# It displays that values are balanced","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.33158Z","iopub.execute_input":"2025-09-20T11:47:54.331942Z","iopub.status.idle":"2025-09-20T11:47:54.351435Z","shell.execute_reply.started":"2025-09-20T11:47:54.331911Z","shell.execute_reply":"2025-09-20T11:47:54.350299Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As our data is now transformed and is ready for Data Visulaization and ML Model Creation. ","metadata":{}},{"cell_type":"markdown","source":"# Outliers","metadata":{}},{"cell_type":"code","source":"def iqr_limits(data, col):\n    q1 = data[col].quantile(0.25)\n    q3 = data[col].quantile(0.75)\n    \n    iqr = q3 - q1\n    lower = q1 - (1.5 * iqr)\n    upper = q3 + (1.5 * iqr)\n    return upper, lower","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.352453Z","iopub.execute_input":"2025-09-20T11:47:54.352809Z","iopub.status.idle":"2025-09-20T11:47:54.371682Z","shell.execute_reply.started":"2025-09-20T11:47:54.35278Z","shell.execute_reply":"2025-09-20T11:47:54.370481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skew, not_skew = [], []\n\nX = data.drop('Class', axis=1)\nY = data['Class']\n\nfor col in X.columns:\n    sk = data[col].skew()\n    print(f\"Column [{col}] is {sk:.2f}\", end = '\\t')\n    if sk > - 0.5 and sk < 0.5:\n        print(f\"{col} is Symmetric\")\n        not_skew.append(col)\n    elif sk > -1 and sk < -1:\n        print(f\"{col} is Moderately Skewed\")\n        skew.append(col)\n    else:\n        print(f\"{col} is Skewed\")\n        skew.append(col)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.372694Z","iopub.execute_input":"2025-09-20T11:47:54.372957Z","iopub.status.idle":"2025-09-20T11:47:54.416013Z","shell.execute_reply.started":"2025-09-20T11:47:54.372936Z","shell.execute_reply":"2025-09-20T11:47:54.41485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def iqr_method(data, cols):\n    results = {}\n    for col in cols:\n        q1 = data[col].quantile(0.25)\n        q3 = data[col].quantile(0.75)\n    \n        iqr = q3 - q1\n        lower = q1 - (1.5 * iqr)\n        upper = q3 + (1.5 * iqr)\n        outlier = data[(data[col] < lower) | (data[col] > upper)]\n        results[col] = len(outlier)\n        print(f\"The {col} : {len(outlier)} outliers or {(len(outlier)/len(data))* 100} % outliers\")\n        data[col] = np.where(data[col] > upper, upper, np.where(data[col] < lower, lower, data[col]))\n        print(\"After Imputation: \")\n        outlier = data[(data[col] < lower) | (data[col] > upper)]\n        print(f\"The {col} : {len(outlier)} outliers or {(len(outlier)/len(data)) * 100} % outliers\")\n        print(\"--------------------------------------------------------------------\")\n    # return outlier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.417049Z","iopub.execute_input":"2025-09-20T11:47:54.417339Z","iopub.status.idle":"2025-09-20T11:47:54.425891Z","shell.execute_reply.started":"2025-09-20T11:47:54.41729Z","shell.execute_reply":"2025-09-20T11:47:54.4247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Columns that are not skew are {len(not_skew)}: \")\nprint(not_skew)\nprint(\"-----------------------------------\")\nprint(f\"Columns that are skewed {len(skew)}: \")\nprint(skew)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.427189Z","iopub.execute_input":"2025-09-20T11:47:54.427579Z","iopub.status.idle":"2025-09-20T11:47:54.445712Z","shell.execute_reply.started":"2025-09-20T11:47:54.427554Z","shell.execute_reply":"2025-09-20T11:47:54.444718Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Skewed Data","metadata":{}},{"cell_type":"code","source":"# Before outlier Removal\nplt.figure(figsize=(14, 6))\nk=1\nfor col in skew:\n    plt.subplot(2, 4, k)\n    sns.boxplot(data= data, x=col, orient='v')\n    plt.xlabel(col)\n    plt.grid()\n    plt.legend()\n    k = k+1\nplt.tight_layout()\nplt.show()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.448902Z","iopub.execute_input":"2025-09-20T11:47:54.449676Z","iopub.status.idle":"2025-09-20T11:47:54.823669Z","shell.execute_reply.started":"2025-09-20T11:47:54.449648Z","shell.execute_reply":"2025-09-20T11:47:54.822636Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# skew_out = \niqr_method(data, skew)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.825061Z","iopub.execute_input":"2025-09-20T11:47:54.825334Z","iopub.status.idle":"2025-09-20T11:47:54.871795Z","shell.execute_reply.started":"2025-09-20T11:47:54.825314Z","shell.execute_reply":"2025-09-20T11:47:54.870821Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# After Outlier Removal\nplt.figure(figsize=(14, 6))\nk=1\nfor col in skew:\n    plt.subplot(3, 3, k)\n    sns.boxplot(data= data, x=col, orient='v')\n    plt.xlabel(col)\n    plt.grid()\n    plt.legend()\n    k = k+1\nplt.tight_layout()\nplt.show()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:54.872732Z","iopub.execute_input":"2025-09-20T11:47:54.872983Z","iopub.status.idle":"2025-09-20T11:47:55.206823Z","shell.execute_reply.started":"2025-09-20T11:47:54.872963Z","shell.execute_reply":"2025-09-20T11:47:55.205892Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(18, 8))\nk=1\nfor col in skew:\n    upper, lower = iqr_limits(data, col)\n    plt.subplot(4, 2, k)\n    sns.kdeplot(data[col], fill = True, label=f\"Imputed {col}\")\n    sns.kdeplot(data2[col], fill = True, label=col)\n    plt.axvline(x=lower, linestyle='--', color='r', label='Lower Limit')\n    plt.axvline(x=upper, linestyle='--', color='g', label='Upper Limit')\n    plt.xlabel(col)\n    plt.grid()\n\n    # plt.xlim([(data2[col].min()) , data2[col].max()])\n    plt.legend()\n    k +=1\n\nplt.tight_layout()\nplt.show()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:55.207777Z","iopub.execute_input":"2025-09-20T11:47:55.208028Z","iopub.status.idle":"2025-09-20T11:47:58.397308Z","shell.execute_reply.started":"2025-09-20T11:47:55.207999Z","shell.execute_reply":"2025-09-20T11:47:58.396357Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Using Box Plot to Visualize the Outliers. ","metadata":{}},{"cell_type":"markdown","source":"## Non-skewed Data","metadata":{}},{"cell_type":"code","source":"# Before outlier Removal\nplt.figure(figsize=(26, 18))\nk=1\nfor col in not_skew:\n    plt.subplot(7, 4, k)\n    sns.boxplot(data= data, x=col, orient='v')\n    plt.xlabel(col)\n    plt.grid()\n    plt.legend()\n    k = k+1\nplt.tight_layout()\nplt.show()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:47:58.398242Z","iopub.execute_input":"2025-09-20T11:47:58.398523Z","iopub.status.idle":"2025-09-20T11:48:00.333932Z","shell.execute_reply.started":"2025-09-20T11:47:58.398502Z","shell.execute_reply":"2025-09-20T11:48:00.332933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def detect_using_zscore(data, col, threshold=3):\n    \n    mean = data[col].mean()\n    std = data[col].std()\n        \n    if std == 0:\n        print(f\"Column '{col}' has zero standard deviation. No outliers possible.\")\n        return 0,0\n\n    lower_limit = mean - threshold * std\n    upper_limit = mean + threshold * std\n    return lower_limit, upper_limit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:00.335178Z","iopub.execute_input":"2025-09-20T11:48:00.335463Z","iopub.status.idle":"2025-09-20T11:48:00.341362Z","shell.execute_reply.started":"2025-09-20T11:48:00.335443Z","shell.execute_reply":"2025-09-20T11:48:00.340035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(48, 30))\nk=1\nfor col in not_skew:\n    upper, lower = iqr_limits(data, col)\n    plt.subplot(9, 3, k)\n    # sns.kdeplot(data[col], fill = True, label=f\"Imputed {col}\")\n    sns.kdeplot(data[col], fill = True, label=col)\n    plt.axvline(x=lower, linestyle='--', color='r', label='Lower Limit')\n    plt.axvline(x=upper, linestyle='--', color='g', label='Upper Limit')\n    plt.xlabel(col)\n    plt.grid()\n\n    # plt.xlim([(data2[col].min()) , data2[col].max()])\n    plt.legend()\n    k +=1\n\nplt.tight_layout()\nplt.show()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:00.342576Z","iopub.execute_input":"2025-09-20T11:48:00.34286Z","iopub.status.idle":"2025-09-20T11:48:09.825899Z","shell.execute_reply.started":"2025-09-20T11:48:00.342838Z","shell.execute_reply":"2025-09-20T11:48:09.824915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndef detect_and_impute_outliers(data, columns, threshold=3):\n    if isinstance(columns, set):\n        columns = list(columns)\n    \n    for col in columns:\n        if col not in data.columns:\n            print(f\"Column '{col}' not found in data. Skipping.\")\n            continue\n        \n        mean = data[col].mean()\n        std = data[col].std()\n        \n        if std == 0:\n            print(f\"Column '{col}' has zero standard deviation. No outliers possible.\")\n            continue\n        \n        lower_limit = mean - threshold * std\n        upper_limit = mean + threshold * std\n        \n        # Count initial outliers\n        num_outliers = ((data[col] < lower_limit) | (data[col] > upper_limit)).sum()\n        \n        print(f\"For column '{col}':\")\n        # print(f\"  Mean: {mean:.4f}\")\n        # print(f\"  Std: {std:.4f}\")\n        print(f\"  Lower limit (outlier if below): {lower_limit:.4f}\")\n        print(f\"  Upper limit (outlier if above): {upper_limit:.4f}\")\n        print(f\"  Number of outliers before imputation: {num_outliers}\")\n        \n        # Impute by clipping\n        data[col] = np.where(data[col] > upper_limit, upper_limit, np.where(data[col] < lower_limit, lower_limit, data[col]))\n        \n        # Recount outliers to confirm\n        num_outliers_after = ((data[col] < lower_limit) | (data[col] > upper_limit)).sum()\n        print(f\"  Number of outliers after imputation: {num_outliers_after}\")\n        print(\"---\"*15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:09.826946Z","iopub.execute_input":"2025-09-20T11:48:09.827445Z","iopub.status.idle":"2025-09-20T11:48:09.83842Z","shell.execute_reply.started":"2025-09-20T11:48:09.827416Z","shell.execute_reply":"2025-09-20T11:48:09.837303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detect_and_impute_outliers(data, not_skew)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:09.839407Z","iopub.execute_input":"2025-09-20T11:48:09.840254Z","iopub.status.idle":"2025-09-20T11:48:09.920285Z","shell.execute_reply.started":"2025-09-20T11:48:09.840153Z","shell.execute_reply":"2025-09-20T11:48:09.919229Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Visulization","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\nv = []\nfor i in range(1, 29):\n    add = \"V\" + str(i)\n    v.append(add)\n    \n# from matplotlib import pyplot as plt\nfig = plt.figure(figsize=(20, 12))\nj = 1\nfor val in v:\n    plt.subplot(4, 7, j)\n    sns.kdeplot(data[val], fill = True, label=val)\n    plt.xlabel(val)\n    plt.grid()\n    plt.legend()\n    j = j+1\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:09.921301Z","iopub.execute_input":"2025-09-20T11:48:09.921854Z","iopub.status.idle":"2025-09-20T11:48:19.261126Z","shell.execute_reply.started":"2025-09-20T11:48:09.921819Z","shell.execute_reply":"2025-09-20T11:48:19.259797Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.kdeplot(data=data, x='Amount', fill=True)\nplt.grid()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:19.26233Z","iopub.execute_input":"2025-09-20T11:48:19.262641Z","iopub.status.idle":"2025-09-20T11:48:20.260456Z","shell.execute_reply.started":"2025-09-20T11:48:19.262619Z","shell.execute_reply":"2025-09-20T11:48:20.259247Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"binn = [0, 1000, 2500, 5000, 10000, 15000, 20000, 25000]\nlabels = ['Under 1k', '1k to 2.5k', '2.5k to 5k', '5k to 10k', '10k to 15k', '15k to 20k', '20k to 25k']\ndata['Amount_in_bins'] = pd.cut(data['Amount'], labels = labels, bins=binn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:20.261457Z","iopub.execute_input":"2025-09-20T11:48:20.261717Z","iopub.status.idle":"2025-09-20T11:48:20.271455Z","shell.execute_reply.started":"2025-09-20T11:48:20.261697Z","shell.execute_reply":"2025-09-20T11:48:20.270215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.histplot(data['Amount_in_bins'])\nplt.xticks(rotation=45)\nplt.xlabel(\"Amount in Categories\")\nplt.ylabel(\"No. of Transactions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:20.272682Z","iopub.execute_input":"2025-09-20T11:48:20.273059Z","iopub.status.idle":"2025-09-20T11:48:21.116755Z","shell.execute_reply.started":"2025-09-20T11:48:20.273026Z","shell.execute_reply":"2025-09-20T11:48:21.115877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\ncolor = ['purple', 'orange', 'purple', 'orange']\n(data.groupby('Amount_in_bins')['Class'].value_counts()).plot(kind='bar', color=color)\nplt.xticks(rotation=90)\nplt.grid()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:21.118013Z","iopub.execute_input":"2025-09-20T11:48:21.118336Z","iopub.status.idle":"2025-09-20T11:48:21.265564Z","shell.execute_reply.started":"2025-09-20T11:48:21.118314Z","shell.execute_reply":"2025-09-20T11:48:21.264486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.groupby('Amount_in_bins')['Class'].value_counts()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:21.267081Z","iopub.execute_input":"2025-09-20T11:48:21.267475Z","iopub.status.idle":"2025-09-20T11:48:21.285706Z","shell.execute_reply.started":"2025-09-20T11:48:21.267443Z","shell.execute_reply":"2025-09-20T11:48:21.284509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"i=0\nfraud_by_bin = data.groupby('Amount_in_bins')['Class'].value_counts()\nfor val in labels:\n    non_fraud = fraud_by_bin[i]/(fraud_by_bin[i] + fraud_by_bin[i+1])\n    fraud = fraud_by_bin[i+1]/(fraud_by_bin[i] + fraud_by_bin[i+1])\n    print(f\"Chances of Fraud when transaction of {val} is made is : {fraud*100:.2f}%\")\n    print(f\"Chances of not_Fraud when transaction of {val} is made is : {non_fraud*100:.2f}%\")\n    i=i+2\n    print(\"----\"*20)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:21.287217Z","iopub.execute_input":"2025-09-20T11:48:21.287557Z","iopub.status.idle":"2025-09-20T11:48:21.305698Z","shell.execute_reply.started":"2025-09-20T11:48:21.287533Z","shell.execute_reply":"2025-09-20T11:48:21.304302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_num = [col for col in data.columns if col != 'Amount_in_bins']\nplt.figure(figsize=(20,12), dpi =500)\nsns.heatmap(data[all_num].corr(), annot=True,fmt=\".2f\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:21.306792Z","iopub.execute_input":"2025-09-20T11:48:21.307835Z","iopub.status.idle":"2025-09-20T11:48:23.433981Z","shell.execute_reply.started":"2025-09-20T11:48:21.307809Z","shell.execute_reply":"2025-09-20T11:48:23.43316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data['Class'].value_counts().plot(kind='pie', labels=[ 'Not Fraud', 'Fraud'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:23.435117Z","iopub.execute_input":"2025-09-20T11:48:23.435441Z","iopub.status.idle":"2025-09-20T11:48:24.061427Z","shell.execute_reply.started":"2025-09-20T11:48:23.435418Z","shell.execute_reply":"2025-09-20T11:48:24.060469Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nX = data2.drop('Class', axis=1)\nY = data2['Class']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\nst = StandardScaler()\nX_train = st.fit_transform(X_train)\nX_test = st.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:24.065328Z","iopub.execute_input":"2025-09-20T11:48:24.065632Z","iopub.status.idle":"2025-09-20T11:48:24.11316Z","shell.execute_reply.started":"2025-09-20T11:48:24.065611Z","shell.execute_reply":"2025-09-20T11:48:24.112141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Section 3: Machine Learning Model Training\n\n# Import necessary libraries for modeling\nimport pandas as pd\nimport os\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n\n# Initialize a dictionary to hold our models\nmodels = {\n    'Logistic Regression': LogisticRegression(solver='liblinear', random_state=42),\n    'Random Forest': RandomForestClassifier(random_state=42),\n    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss'),  # eval_metric for binary classification\n    'LightGBM': LGBMClassifier(random_state=42),\n    'CatBoost': CatBoostClassifier(random_state=42, verbose=0)  # verbose=0 to suppress training output\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:24.114036Z","iopub.execute_input":"2025-09-20T11:48:24.1143Z","iopub.status.idle":"2025-09-20T11:48:24.121554Z","shell.execute_reply.started":"2025-09-20T11:48:24.114279Z","shell.execute_reply":"2025-09-20T11:48:24.120437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train each model and save its predictions and probabilities\nfor name, model in models.items():\n    print(f'\\n--- Training {name} ---')\n    \n    model.fit(X_train, y_train)\n    \n    # Make predictions on the test set\n    y_pred = model.predict(X_test)\n    y_proba = model.predict_proba(X_test)[:, 1]  # Probability of the positive class\n    \n    # Clean model name for file saving\n    model_name_cleaned = name.replace(' ', '_').lower()\n    \n    # Save predictions and probabilities to CSV files in current working directory\n    os.makedirs(\"y_Predictions\", exist_ok=True)\n    os.makedirs(\"y_Probabilities\", exist_ok=True)\n    pd.DataFrame(y_pred).to_csv(f'y_Predictions/y_pred_{model_name_cleaned}.csv', index=False)\n    pd.DataFrame(y_proba).to_csv(f'y_Probabilities/y_proba_{model_name_cleaned}.csv', index=False)\n    \n    print(f'{name} training complete. Predictions and probabilities saved.')\n\nprint('\\nAll selected models have been trained and their predictions/probabilities saved for evaluation.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:48:24.122643Z","iopub.execute_input":"2025-09-20T11:48:24.122923Z","iopub.status.idle":"2025-09-20T11:49:06.267562Z","shell.execute_reply.started":"2025-09-20T11:48:24.122901Z","shell.execute_reply":"2025-09-20T11:49:06.266374Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries for evaluation\nimport pandas as pd\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score,\n    f1_score, roc_auc_score, confusion_matrix,\n    ConfusionMatrixDisplay, roc_curve\n)\n\nimport matplotlib\nmatplotlib.use(\"Agg\")  # Use a non-interactive backend\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Define the list of models for which we have predictions\nmodels_to_evaluate = [\n    \"logistic_regression\",\n    \"random_forest\",\n    \"xgboost\",\n    \"lightgbm\",\n    \"catboost\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:49:06.268577Z","iopub.execute_input":"2025-09-20T11:49:06.268859Z","iopub.status.idle":"2025-09-20T11:49:06.275724Z","shell.execute_reply.started":"2025-09-20T11:49:06.268838Z","shell.execute_reply":"2025-09-20T11:49:06.274452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nresults = {}\n\nprint(\"\\n--- Evaluating Model Performance ---\")\n\nfor model_name_cleaned in models_to_evaluate:\n    model_display_name = model_name_cleaned.replace(\"_\", \" \").title()\n    print(f\"\\nEvaluating {model_display_name}...\")\n\n    # Load predictions and probabilities from current working directory\n    y_pred = pd.read_csv(f\"y_Predictions/y_pred_{model_name_cleaned}.csv\").values.ravel()\n    y_proba = pd.read_csv(f\"y_Probabilities/y_proba_{model_name_cleaned}.csv\").values.ravel()\n\n    # Calculate evaluation metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    roc_auc = roc_auc_score(y_test, y_proba)\n\n    results[model_display_name] = {\n        \"Accuracy\": accuracy,\n        \"Precision\": precision,\n        \"Recall\": recall,\n        \"F1-Score\": f1,\n        \"ROC-AUC\": roc_auc\n    }\n\n    print(f\" Accuracy:  {accuracy:.4f}\")\n    print(f\" Precision: {precision:.4f}\")\n    print(f\" Recall:    {recall:.4f}\")\n    print(f\" F1-Score:  {f1:.4f}\")\n    print(f\" ROC-AUC:   {roc_auc:.4f}\")\n\n    # Plot Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n\n    fig, ax = plt.subplots(figsize=(6, 6))\n    disp.plot(cmap=plt.cm.Blues, ax=ax)\n    ax.set_title(f\"Confusion Matrix for {model_display_name}\")\n\n    os.makedirs(\"Confusion Matrix\", exist_ok=True)\n    plt.savefig(f\"Confusion Matrix/confusion_matrix_{model_name_cleaned}.png\")\n    plt.close(fig)  # Close the plot to free memory\n\n    print(f\" Confusion matrix saved as confusion_matrix_{model_name_cleaned}.png\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:49:06.277311Z","iopub.execute_input":"2025-09-20T11:49:06.277662Z","iopub.status.idle":"2025-09-20T11:49:07.173716Z","shell.execute_reply.started":"2025-09-20T11:49:06.277636Z","shell.execute_reply":"2025-09-20T11:49:07.172493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display all results in a DataFrame for easy comparison\nresults_df = pd.DataFrame(results).T\n\nprint(\"\\n--- Comprehensive Model Evaluation Results ---\")\nprint(results_df.sort_values(by=\"F1-Score\", ascending=False))\n\n# Save the comprehensive results to a CSV file in current working directory\nos.makedirs(\"Evaluation Result\", exist_ok=True)\nresults_df.to_csv(\"Evaluation Result/model_evaluation_results.csv\")\nprint(\"\\nAll model evaluation results saved to model_evaluation_results.csv\")\n\n# Optional: Plot ROC curves for all models for visual comparison\nplt.figure(figsize=(10, 8))\n\nfor model_name_cleaned in models_to_evaluate:\n    model_display_name = model_name_cleaned.replace(\"_\", \" \").title()\n    y_proba = pd.read_csv(f\"y_Probabilities/y_proba_{model_name_cleaned}.csv\").values.ravel()\n\n    fpr, tpr, _ = roc_curve(y_test, y_proba)\n    plt.plot(\n        fpr, tpr,\n        label=f\"{model_display_name} (AUC = {roc_auc_score(y_test, y_proba):.2f})\"\n    )\n    plt.plot([0, 1], [0, 1], \"k--\", label=\"Random (AUC = 0.50)\")\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"ROC Curve Comparison\")\n    plt.legend(loc=\"lower right\")\n    plt.grid(True)\n    \n    \n    os.makedirs(\"figures\", exist_ok=True)\n    plt.savefig(f\"figures/confusion_matrix_{model_name_cleaned}.png\")\n    plt.close()  # Close the plot to free memory\n\nprint(\"ROC curve comparison plot saved as roc_curve_comparison.png\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-20T11:49:07.174556Z","iopub.execute_input":"2025-09-20T11:49:07.174811Z","iopub.status.idle":"2025-09-20T11:49:18.215538Z","shell.execute_reply.started":"2025-09-20T11:49:07.174792Z","shell.execute_reply":"2025-09-20T11:49:18.213994Z"}},"outputs":[],"execution_count":null}]}